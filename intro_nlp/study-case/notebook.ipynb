{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a75a29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lucky\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lucky\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google_play_scraper import app, reviews, Sort, reviews_all\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import datetime as dict\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c494488",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapreview = reviews_all(\n",
    "    'com.byu.id',\n",
    "    lang=\"id\",\n",
    "    country='id',\n",
    "    sort=Sort.MOST_RELEVANT,\n",
    "    count=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc706dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menyimpan ulaasan dalam file CSV\n",
    "import csv\n",
    "\n",
    "with open('ulasan_aplikasi.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Review'])\n",
    "    for review in scrapreview:\n",
    "        writer.writerow([review['content']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "790f16f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dataset\n",
    "app_reviews_df = pd.DataFrame(scrapreview)\n",
    "app_reviews_df.shape\n",
    "app_reviews_df.head()\n",
    "app_reviews_df.to_csv(\"ulasan_aplikasi.csv\", index=False)\n",
    "\n",
    "# Membuat DataFrame dari hasil scrapreview\n",
    "app_reviews_df = pd.DataFrame(scrapreview)\n",
    "\n",
    "jumlah_ulasan, jumlah_kolom = app_reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed8965c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36014f67-2f37-4034-8cfc-a39f76f01ed5</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>sinyal bagus tapi buat buka apk nya lemot bang...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.63.1</td>\n",
       "      <td>2025-10-15 16:06:42</td>\n",
       "      <td>Hallo Kak. Maaf banget udah bikin gak nyaman. ...</td>\n",
       "      <td>2025-10-15 16:08:06</td>\n",
       "      <td>1.63.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>269f6fd9-615f-4ed6-9dd8-fd9411a82caf</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>untuk developer ,aplikasinya lemot dikit dikit...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.63.0</td>\n",
       "      <td>2025-10-14 21:42:53</td>\n",
       "      <td>Hai Kak, maaf ya udah bikin ga nyaman :( Terka...</td>\n",
       "      <td>2025-10-14 21:43:41</td>\n",
       "      <td>1.63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce1e598d-e54f-4a8d-9d1c-5fea795a39cc</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>udh hampir 1 tahun pake by u, aplikasi nya ber...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1.63.0</td>\n",
       "      <td>2025-10-12 20:18:16</td>\n",
       "      <td>Hai Kak, maaf ya udah bikin ga nyaman :( Terka...</td>\n",
       "      <td>2025-10-12 20:19:00</td>\n",
       "      <td>1.63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>695ba5b6-4df5-467d-80f5-afa1a7172c28</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>KECEWA, paket \"Yang Bikin Makin Aman Jaya\" tib...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1.63.0</td>\n",
       "      <td>2025-10-13 08:38:39</td>\n",
       "      <td>Hai Kak, maaf ya udah bikin ga nyaman :( Terka...</td>\n",
       "      <td>2025-10-13 10:40:59</td>\n",
       "      <td>1.63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47343457-0877-41d5-97ba-39e07d4882e6</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>kenapa sih tiap buka apk nya tibaÂ² keluar send...</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1.63.0</td>\n",
       "      <td>2025-10-11 21:00:00</td>\n",
       "      <td>Hai Kak, maaf nih terkait kendala jaringan, bi...</td>\n",
       "      <td>2025-10-11 21:03:03</td>\n",
       "      <td>1.63.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               reviewId  ... appVersion\n",
       "0  36014f67-2f37-4034-8cfc-a39f76f01ed5  ...     1.63.1\n",
       "1  269f6fd9-615f-4ed6-9dd8-fd9411a82caf  ...     1.63.0\n",
       "2  ce1e598d-e54f-4a8d-9d1c-5fea795a39cc  ...     1.63.0\n",
       "3  695ba5b6-4df5-467d-80f5-afa1a7172c28  ...     1.63.0\n",
       "4  47343457-0877-41d5-97ba-39e07d4882e6  ...     1.63.0\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "243ee8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153000 entries, 0 to 152999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   reviewId              153000 non-null  object        \n",
      " 1   userName              153000 non-null  object        \n",
      " 2   userImage             153000 non-null  object        \n",
      " 3   content               152999 non-null  object        \n",
      " 4   score                 153000 non-null  int64         \n",
      " 5   thumbsUpCount         153000 non-null  int64         \n",
      " 6   reviewCreatedVersion  130007 non-null  object        \n",
      " 7   at                    153000 non-null  datetime64[ns]\n",
      " 8   replyContent          141957 non-null  object        \n",
      " 9   repliedAt             141957 non-null  datetime64[ns]\n",
      " 10  appVersion            130007 non-null  object        \n",
      "dtypes: datetime64[ns](2), int64(2), object(7)\n",
      "memory usage: 12.8+ MB\n"
     ]
    }
   ],
   "source": [
    "app_reviews_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7316c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = app_reviews_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ae118fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.drop_duplicates()\n",
    "\n",
    "jumlah_ulasan_setelah_hapus_duplikat, jumlah_kolom_setelah_hapus_duplikat = clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13460ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningText(text):\n",
    "    text = re.sub(r\"@[A-Za-z0-9]+\", '', text) # Delete mention\n",
    "    text = re.sub(r\"#[A-Za-z0-9]+\", '', text) # Delete hashtag\n",
    "    text = re.sub(r\"RT[\\s]\", \"\", text) # Delete RT\n",
    "    text = re.sub(r\"http\\S+\", \"\", text) # Delete Link\n",
    "    text = re.sub(r\"[0-9]+\", \"\", text) # Delete Numbers\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text) # Delete character except huruf and number\n",
    "\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation)) # Menghapus semua tanda baca\n",
    "    text = text.strip(\" \")\n",
    "    \n",
    "    return text\n",
    "\n",
    "def casefoldingText(text):\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def tokenizingText(text):\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "def filteringText(text):\n",
    "    listStopwords = set(stopwords.words(\"indonesian\"))\n",
    "    listStopwords1 = set(stopwords.words(\"english\"))\n",
    "    listStopwords.update(listStopwords1)\n",
    "    listStopwords.update(['iya','yaa','gak','nya','na','sih','ku',\"di\",\"ga\",\"ya\",\"gaa\",\"loh\",\"kah\",\"woi\",\"woii\",\"woy\"])\n",
    "    filtered = []\n",
    "    for txt in text:\n",
    "        if txt not in listStopwords:\n",
    "            filtered.append(txt)\n",
    "    text = filtered\n",
    "\n",
    "    return text\n",
    "\n",
    "def stemmingText(text):\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "\n",
    "    words = text.split()\n",
    "\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    stemmed_text = \" \".join(stemmed_words)\n",
    "\n",
    "    return stemmed_text\n",
    "\n",
    "def toSentence(list_words):\n",
    "    sentence = \" \".join(word for word in list_words)\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3654eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "slangwords = {\"@\": \"di\", \"abis\": \"habis\", \"wtb\": \"beli\", \"masi\": \"masih\", \"wts\": \"jual\", \"wtt\": \"tukar\", \"bgt\": \"banget\", \"maks\": \"maksimal\"}\n",
    "def fix_slangwords(text):\n",
    "    words = text.split()\n",
    "    fixed_words = []\n",
    "\n",
    "    for word in words:\n",
    "        if word.lower() in slangwords:\n",
    "            fixed_words.append(slangwords[word.lower()])\n",
    "        else:\n",
    "            fixed_words.append(word)\n",
    "\n",
    "    fixed_text = \" \".join(fixed_words)\n",
    "    return fixed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf13f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# membersikan text dan menyimpannya di kolom \"text_clean\"\n",
    "clean_df['text_clean'] = clean_df['content'].apply(cleaningText)\n",
    "\n",
    "# Mengubah huruf dalam teks menjadi hurf kecil dan menyimpannya di 'text_casefoldingText'\n",
    "clean_df['text_casefoldingText'] = clean_df['text_clean'].apply(casefoldingText)\n",
    "\n",
    "# Mengganti kata kata slang dengan kata kata standar dan menyimpannya di 'text_slangwords'\n",
    "clean_df['text_slangwords'] = clean_df['text_casefoldingText'].apply(fix_slangwords)\n",
    "\n",
    "# Memecah teks menjadi token (kata-kata) dan menyimpannya di 'text_tekenizingText'\n",
    "clean_df['text_tokenizingText'] = clean_df['text_slangwords'].apply(tokenizingText)\n",
    "\n",
    "# Menghapus kata kata stop (kata-kata umum) dan menyimpannya di 'text_stopword'\n",
    "clean_df['text_stopword'] = clean_df['text_tokenizingText'].apply(filteringText)\n",
    "\n",
    "# Menggabungkan token-token menjadi kalimat dan menyimpanya di 'text_akhir'\n",
    "clean_df[\"text_akhir\"] = clean_df['text_stopword'].apply(toSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "386dfd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from io import StringIO\n",
    " \n",
    "# Membaca data kamus kata-kata positif dari GitHub\n",
    "lexicon_positive = {}\n",
    " \n",
    "response = requests.get('https://raw.githubusercontent.com/angelmetanosaa/dataset/main/lexicon_positive.csv')\n",
    "# Mengirim permintaan HTTP untuk mendapatkan file CSV dari GitHub\n",
    " \n",
    "if response.status_code == 200:\n",
    "    # Jika permintaan berhasil\n",
    "    reader = csv.reader(StringIO(response.text), delimiter=',')\n",
    "    # Membaca teks respons sebagai file CSV menggunakan pembaca CSV dengan pemisah koma\n",
    " \n",
    "    for row in reader:\n",
    "        # Mengulangi setiap baris dalam file CSV\n",
    "        lexicon_positive[row[0]] = int(row[1])\n",
    "        # Menambahkan kata-kata positif dan skornya ke dalam kamus lexicon_positive\n",
    "else:\n",
    "    print(\"Failed to fetch positive lexicon data\")\n",
    " \n",
    "# Membaca data kamus kata-kata negatif dari GitHub\n",
    "lexicon_negative = {}\n",
    " \n",
    "response = requests.get('https://raw.githubusercontent.com/angelmetanosaa/dataset/main/lexicon_negative.csv')\n",
    "# Mengirim permintaan HTTP untuk mendapatkan file CSV dari GitHub\n",
    " \n",
    "if response.status_code == 200:\n",
    "    # Jika permintaan berhasil\n",
    "    reader = csv.reader(StringIO(response.text), delimiter=',')\n",
    "    # Membaca teks respons sebagai file CSV menggunakan pembaca CSV dengan pemisah koma\n",
    " \n",
    "    for row in reader:\n",
    "        # Mengulangi setiap baris dalam file CSV\n",
    "        lexicon_negative[row[0]] = int(row[1])\n",
    "        # Menambahkan kata-kata negatif dan skornya dalam kamus lexicon_negative\n",
    "else:\n",
    "    print(\"Failed to fetch negative lexicon data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f021c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menentukan polaritas sentimaen dari tweet\n",
    "\n",
    "def sentiment_analysis_lexicon_indonesia(text):\n",
    "    score = 0\n",
    "\n",
    "    for word in text:\n",
    "        if (word in lexicon_positive):\n",
    "            score = score + lexicon_positive[word]\n",
    "\n",
    "    for word in text:\n",
    "        if(word in lexicon_negative):\n",
    "            score = score + lexicon_negative[word]\n",
    "\n",
    "    polarity = \"\"\n",
    "\n",
    "    if(score >= 0):\n",
    "        polarity = \"positive\"\n",
    "    elif (score < 0):\n",
    "        polarity = \"negative\"\n",
    "\n",
    "    return score, polarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d838729d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity\n",
      "positive    63165\n",
      "negative    56953\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "results = clean_df['text_stopword'].apply(sentiment_analysis_lexicon_indonesia)\n",
    "results = list(zip(*results))\n",
    "clean_df['polarity_score'] = results[0]\n",
    "clean_df['polarity'] = results[1]\n",
    "print(clean_df['polarity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752ec5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
